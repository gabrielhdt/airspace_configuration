\documentclass[oneside,twocolumn]{article}

\usepackage{fontspec}
\usepackage{polyglossia}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{unicode-math}
\usepackage{amsmath,amsthm,stmaryrd}
\usepackage{algorithm,algpseudocode}
\usepackage{paralist}
\usepackage{titlesec}

\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\first}{first}
\DeclareMathOperator{\state}{state}

% Headings customisation
\titleformat*{\section}{\Large\scshape\center}
\renewcommand{\thesection}{\Roman{section}}
\renewcommand{\thesubsection}{\Alph{subsection}}


\title{Monte Carlo tree search compared to A\(^*\) in airspace configuration
decision problem}
\author{Gabriel~Hondet, Beno\^{\i}t Viry}
\date{\today}
\pagestyle{headings}

\begin{document}

\maketitle

\begin{abstract}
  A nice abstract
\end{abstract}


\section*{Notations}
\begin{compactitem}
  \item $m$: elementary module;
  \item $S$: sector control position, group of modules;
  \item $P$: partition of the airspace, group of sectors;
  \item $t$: current time;
  \item $C(P, t)$: cost of a given partition $P$ at time $t$;
  \item \(C_{tr}(P_1, P_2)\): cost of transition between partitions \(P_1\) and
    \(P_2\);
  \item \(\pi = [P_1, \dots, P_n]\): a sequence of partitions (called \emph{path}
      in the tree search algorithms);
  \item \(f(\pi)\): cost associated to sequence of partitions \(\pi\);
  \item \(\mathcal{N}\): the set of nodes;
  \item \(u, v \in \mathcal{N}^2\): nodes
  \item $h \colon \mathcal{N} \to \mathbb{R}^+$: heuristic estimating the cost
    from a node \(u\) to a final node;
  \item \(\mu_v\): mean value of outcomes of simulations run through or from a
    node \(v\);
  \item \(T_v\): number of simulations run through or from a node \(v\);
  \item \(\first(\ell)\): returns the first element of \(\ell\).
\end{compactitem}

\section{Introduction}
The airspace is divided into sectors, themselves divided into elementary
modules. Each sector is managed by a controller working position composed of two
controllers.
During the day, sectors are split and merged to be able to
manage the varying traffic. Splitting creates smaller sectors and is therefore
used when traffic gets too dense. On the opposite, merging sectors allows fewer
controllers to manage the same airspace, and is therefore used when traffic
becomes sparse.

Currently, configuration is mainly decided on the fly by chief officer (TODO).
This decision is based on the actual workload on each position. In this
approach, future workload estimation is based on the controller's feelings and
it therefore lacks a workload prediction tool.
This papers aims at providing this tool as well as a method offering a smoother
workload during the day.

Several methods have been considered to solve the dynamic airspace configuration
problem, for instance via genetic algorithms in~\cite{sergeeva2017dynamic},
constraint local search in~\cite{jagare2013airspace}, integer linear
programming in~\cite{treimuth2016branch} or dynamic programming
in~\cite{bloem2010dynamic}.

In this paper, a temporal sequence of configuration is provided, as done
in~\cite{treimuth2016branch} or~\cite{sergeeva2017dynamic}.
Two costs are considered to create the sequence, namely the cost
associated to each configuration and a transition cost. The former is based on
the workload estimated for one sector given a neural network
(see~\cite{gianazza2010forecasting}).

The sequence of configurations is represented as a tree. The resulting
sequence will therefore be a path from the root to a leaf of this tree. This
problem is highly combinatorial (partitioning of the airspace). Since stochastic
tree search algorithms, combined with deep neural networks have proved
themselves worthy by outranking the best human player of one of the most highly
combinatorial game which is the game of Go, the Monte Carlo tree
search~\cite{browne2012survey} algorithm is used in this paper to fulfill the
previously mentioned task.



\section{Previous related works}\label{sec:previous_related_works}

The dynamic airspace configuration problem requires a model of the airspace. As
done in~\cite{sergeeva2017dynamic} or~\cite{treimuth2016branch} the airspace
is modelled via a graph. In those graphs, vertices represent elementary modules
and an edge links two adjacent modules. In~\cite{treimuth2016branch}, to be
able to produce a sequence of configurations, the graph is time dependent.
An other way to model the problem is to use a constrained set of
configurations as in~\cite{gianazza2010forecasting} and~\cite{bloem2010dynamic}.
This way any configuration will match specified requirements, which can be
qualified hard constraints.

In most cases the cost of a configuration is based on the workload. Each
approach seems to give their own representation of the workload. For instance,
~\cite{bedouet2016towards} determined workload density proportionally to the time
spent by aircraft in each sector. A simpler version~\cite{sergeeva2017dynamic}
only uses the number of aircraft. On the other hand, more complex methods,
involving many more inputs are also available. For
instance,~\cite{gianazza2010forecasting} used several indicators, such as sector
volume, or vertical incoming flows in the next 15 and 60 minutes. Those
indicators ease the training of a neural network forecasting the workload.

Other soft constraints appear to be relevant to have a better model of
the problem. For instance in~\cite{sergeeva2017dynamic}
and~\cite{bedouet2016towards} a
coordination cost is defined. It represents the surplus of work added by
flights travelling from one sector to an other. The shape of the
resulting sector is considered, as the simpler is
the shape, the easier it is to manage. Complex shapes are therefore avoided,
thanks to the notion of compactness in~\cite{jagare2013airspace} and balconies
in~\cite{sergeeva2017dynamic}. To smooth the transition between two
configurations, the work associated with the reallocation of one or more modules
is evaluated. This can be used in a cost function aimed to be minimised
(in~\cite{bedouet2016towards}).

In this paper, each partition scheme is based upon the number of aircraft in
each
elementary module and the cost of transition from the previous partitioning. The
available partitions come from a predetermined set containing feasible
partitioning.

The Monte Carlo tree search algorithm has been quickly used in two players game.
Only three years after its apparition in 1990, Br\"ugmann applies it to the Go
game in~\cite{brugmann1993mcgo}. While the Monte-Carlo tree search is still
extensively used in two players games (and especially the Go game), its
adaptation to one player game has been worked on. Auer \textit{et al.} propose
an
upper confidence bound formula which appears to be more efficient for one player
games as seen in~\cite{sebag2010fuse}. The introduced formula uses the standard
deviation of the outcome of the simulations.
The latter article also uses the rapid
action value estimation (RAVE) technique to quicken the convergence of the
algorithm. RAVE uses the ``all moves as first'' heuristic, in which all
moves\footnote{a move is informally considered as a decision taken regarding
which state to choose while descending the search tree}
seen during simulations are considered as a first move. This allows the
algorithm to update more statistics in one simulation. Gelly \textit{et al.} use
in~\cite{gelly2012grand} the RAVE technique coupled with several heuristics. The
heuristics bias the initialisaton of a node in the search tree, pre filling its
statistics using prior knowledge of the problem.

\section{Algorithm}

The task of building an optimal sequence of partitions (lowering
as much as possible the workload of each controller) is fulfilled by a
stochastic tree search method, namely the Monte Carlo tree search. To assess the
exactness of the results, an exact method (here A\(^*\)) is used.

\subsection{Monte Carlo tree search}
\subsubsection{Overview}\label{sssec:overview}
Monte-Carlo is a best-first search method using stochastic simulations. The
algorithm is based on the computation of the reward expectancy of paths which
is estimated through Monte-Carlo simulations.
The
algorithm actually uses two trees, an underlying tree associated to the model
(e.g.\ a game tree) and a search tree. The latter is built incrementally, each
step being composed of four phases, namely
\begin{compactenum}
\item\label{it:selection} selection (or tree walk): choosing successively
  most promising nodes from the search tree,
\item\label{it:expansion} expansion: adding new nodes to the search tree,
\item simulation (or random walk): choosing successively nodes from the model
  tree, from the expanded node to a leaf,
\item backpropagation (or backup): applying the result of the simulation to
  the previously selected nodes of the search tree (phases~\ref{it:selection}
  and~\ref{it:expansion}).
\end{compactenum}
Those phases are repeated until a stopping criterion (e.g.\ memory or time) is
reached, resulting in algorithm~\ref{alg:gen_mcts} where the tree policy
aggregates phases 1 and 2 to create a new node of the search tree and the
default policy gives an evaluation of the newly added node.
\begin{algorithm}
  \caption{General MCTS~\cite{browne2012survey}}\label{alg:gen_mcts}
  \begin{algorithmic}
    \Procedure{MctsSearchTree}{$v_0$}
    \While{within computational budget}
    \State{}\(\pi \gets\) \Call{TreePolicy}{$v_0$}
    \State{}\(v \gets \first(\pi)\)
    \State{}\(\Delta \gets\) \Call{DefaultPolicy}{$v$}
    \State{}\Call{Backup}{$\pi$, $\Delta$}
    \EndWhile{}
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

\subsubsection{Extending the search tree}
\paragraph{Selection (algorithm~\ref{alg:tree_pol})}
The aim of the selection is to build a path from the root of the search tree
by choosing successively the most
promising\footnote{i.e.\ possibly leading to the best evaluation} node.
Given a node \(u\) that has previously been selected, the
best node --
according to a \emph{tree policy} -- among the children of \(u\) is
chosen.
This type
of problem can be solved by bandits methods.
Those methods consist in, given a bandit in front of several slot machines
(multi armed bandit), deciding which machine will bring the highest reward
knowing
the past results. The objective of bandits methods is thus to maximise the reward
and minimise the regret of not playing the best machine.

The bandit problem has been applied to MCTS via the Upper Confidence Tree
algorithm in~\cite{kocsis2006bandit} using the UCB1 equation~\ref{eq:ucb1}.
Let \(u\) be the node from which a child \(v\) must be selected to go deeper in
the tree, \(T_u\) the number of simulations carried out from node \(u\)
(which includes any simulation from nodes in any subtree of \(u\)) and
\(\beta\) a chosen constant. The selected child \(v\) is the one maximising the
\emph{UCB1} equation
\begin{equation}
  \label{eq:ucb1}
  \mu_v + 2 \beta \sqrt{\frac{2 \log T_u}{T_v}}
\end{equation}

While the previous equation is well suited for two players games, it can be
tweaked to improve its efficiency in one player games or sequencing problems. An
alternative using the standard deviation \(\sigma_v\) of the outcome of the
previous simulations involving node \(v\) is
proposed in~\cite{sebag2010fuse} called the \emph{UCB1-tuned} equation
\begin{equation}\label{eq:ucb1-tuned}
  \mu_v +
  \beta\sqrt{%
    \frac{\log T_u}{T_v}
    \min\left( \frac{1}{4}, \sigma^2_v +
    \sqrt{%
      \frac{2 \log T_u}{T_v}
    }\right)
  }
\end{equation}
\begin{algorithm}
  \caption{UCT algorithm}\label{alg:tree_pol}
  \begin{algorithmic}
    \Function{TreePolicy}{$\pi$}
    \State{}\(v \gets \first(\pi)\)
    \If{$v$ is terminal}
    \State{}\Return{$\pi$}
    \Else{}
    \If{$v$ is not fully expanded}
    \State{}\Return{\Call{Expand}{$v$} $\cup \pi$}
    \Else{}
    \State{}$f \gets$ \Call{BestChild}{$v$}
    \State{}\Return{%
      \Call{TreePolicy}{$f \cup \pi$}
    }
    \EndIf{}
    \EndIf{}
    \EndFunction{}
  \end{algorithmic}
  \begin{algorithmic}
    \Function{BestChild}{$v$}
    \State{}\Return{$\argmax\{\Call{UCB}{v'} | v' \text{\,children of\,} v \}$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\subparagraph{Exploration exploitation trade-off} The constant \(\beta\) answers
to the exploration-exploitation dilemma. In the UCB1 equations~\ref{eq:ucb1}
and~\ref{eq:ucb1-tuned},
the right hand term increases the UCB value of less explored nodes to consider them
as still promising. A high \(\beta\) value will therefore make the algorithm
prone to try unvisited nodes while a low value will consider almost exclusively
the results obtained so far, even if other paths are better but unexplored.

\paragraph{Expansion (algorithm~\ref{alg:expansion})}
If the selected node has one or more unvisited children, the selection stops and
one of them is added to the search tree randomly, the latter being thus expanded
by this new node.
\begin{algorithm}
  \caption{Expansion}\label{alg:expansion}
  \begin{algorithmic}
    \Function{Expand}{$u$}
    \State{}$\ell \gets \{ v | v \text{\,children of\,} u, T_v = 0 \}$
    \State{}\Return{random element from $\ell$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\subsubsection{Simulation and backpropagation}
The two steps described in this paragraph aim to guess the reward that can be
expected from a path including a given node.
\paragraph{Simulation}
Once a node has been expanded, random nodes are chosen successively until a
terminal state is found. The cost of the resulting path, from the root to the
node is then evaluated and backpropagated to all the ancestors of the expanded
node.

\subparagraph{Heuristic} One might want to bias the randomness while choosing
nodes. This would imply using a heuristic which has to be able to discriminate
a node between its siblings.

\paragraph{Backpropagation}
The backpropagation consists in updating the values required to carry out the
tree policy. The values must be updated incrementally since the backpropagation
function has the current value of the parameters and the result of the
simulation as parameters. Thus, for UCB1 equation, the expected reward (mean)
and the total count are updated this way
\begin{algorithm}
  \caption{UCB1 backpropagation}
  \begin{algorithmic}
    \Procedure{Backpropagate}{$u$, $r$}
    \State{}\(\delta \gets r - \mu_u\)
    \State{}\(\mu_u \gets \mu_u + \frac{\delta}{T_u + 1}\)
    \State{}\(T_u \gets T_u + 1\)
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

For the UCB1-tuned, the standard deviation has to be computed. It results in
algorithm~\ref{alg:backpropagate-tuned} which introduces the value \(m_2(u)\)
associated to a node \(u\) to compute the standard deviation via the formula
\begin{equation}
  \sigma^2_u = \frac{m_2(u)}{T_u}.
\end{equation}
\begin{algorithm}
  \caption{UCB1-tuned backpropagation}\label{alg:backpropagate-tuned}
  \begin{algorithmic}
    \Procedure{Backpropagate}{$u, r$}
    \State{}\(\delta \gets r - \mu_u\)
    \State{}\(\mu_u \gets \mu_u + \frac{\delta}{T_u + 1}\)
    \State{}\(\delta' \gets r - \mu_u\)
    \State{}\(m_2(u) \gets m_2(u) + \delta \delta'\)
    \State{}\(T_u \gets T_u + 1\)
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}


\subsection{Sequence building}
Once the stopping criterium mentioned in~\ref{sssec:overview} is matched, the
sequence of states can be extracted from the search tree.

\subsubsection{Choosing nodes}\label{sssec:node_selection}
To build the final sequence, nodes are chosen according to a criterion.
Chaslot \textit{et al.} in~\cite{chaslot2008progstrat} propose several
methods to select nodes,
\begin{compactitem}
  \item max-child: select the child with highest mean reward;
  \item robust child: select the most visited root child;
  \item secure child: select the child maximising a lower confidence bound.
\end{compactitem}

\subsubsection{Iterative pathfinding}
The path is built iteratively by calling successive Monte Carlo tree searches.
Say an MCTS has been called on a node \(u\). Once a stopping criterium is
matched, a node \(v\) among the ones reachable from \(u\) is selected via one of
the previously mentioned policies. Then the MCTS algorithm is called back with
node \(u\)
as the root node. The path is composed of the successive roots. The algorithm is
described at~\ref{alg:path_building}.
\begin{algorithm}
  \caption{%
    Path building. The {\sc NextNode} (here max-child) function is one among
    those in~\ref{sssec:node_selection}.
  }\label{alg:path_building}
  \begin{algorithmic}
    \Function{MctsSearch}{$u_0, n$}
    \State{}\(u \gets u_0\)
    \State{}\(\pi \gets \{u\}\)
    \For{$i = 1$ to $n$}
      \State{}\Call{MctsSearchTree}{$u$}
      \State{}\(u \gets\)\Call{NextNode}{$u$}
      \State{}\(\pi \gets \pi \cup \{u\}\)
    \EndFor{}
    \State{}\Return{$\pi$}
    \EndFunction{}
    \Function{NextNode}{$u$}
    \State{}\Return{$\argmax\{\mu_v | v \text{\,children of\,} u\}$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}
\subsection{A\(^*\)}
To evaluate the exactness of the paths given by the MCTS algoithm, the A\(^*\)
algorithm is used. A\(^*\) is an exact depth first search pathfinding algorithm
which uses a heuristic function to guide its search. The algorithm is given
in~\ref{alg:astar} where \(u_0\) is the initial state, \(T\) the set of termial
nodes, \(h\) a heuristic function estimating the cost from a state \(u\) given
as argument to a final state, \(k \colon \mathcal{N}^2 \to \mathbb{R}\). The
function \(\first(G)\) returns the first element of \(G\) and
\(f\mathup{-insert}(G, v)\) inserts \(v\) in \(G\) ordering first by \(f\)
increasing then by \(g\) decreasing.
\begin{algorithm}
  \caption{A\(^*\) algorithm~\cite{alliotschiex2002ia&it}}\label{alg:astar}
  \begin{algorithmic}
    \Procedure{A$^*$}{$u_0$}
    \State{}\(G \gets u_0; D \gets \emptyset; g(u_0) \gets 0; f(u_0) \gets 0\)
    \State{}\(\mathup{father}(u_0) \gets \emptyset\)
    \While{$G \neq \emptyset$}
    \State{}\(u \gets \first(G); G \gets G \backslash \{u\}\)
    \State{}\(D \gets D \cup \{u\}\)
    \If{$u \in T$}
    \State{}\Return{father}
    \EndIf{}
    \For{$v$ in childen of $u$}
    \If{$v \notin D \cup G$ or $[g(v) > g(u) + k(u, v)]$}
    \State{}\(g(v) \gets g(u) + k(u, v)\)
    \State{}\(f(v) \gets g(v) + h(v)\)
    \State{}\(\mathup{father}(v) \gets u\)
    \State{}\(f\mathup{-insert}(G, v)\)
    \EndIf{}
    \EndFor{}
    \EndWhile{}
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

\paragraph{Heuristic}
To be sure to have the optimal solution, the heuristic \(h\) has to be
\emph{minimal} i.e.\ let \(h^*\) be the optimal heuristic (the one giving the
true distance from a node to a final state), then for any node \(u\), \(h(u)
\leq h^*(u)\).


\subsection{Theoretical performances}
In this paper, a high branching factor problem is considered.

Let \(H\) be the height of the tree, \(K\) the branching factor.
Then, the complexity of the A\(^*\) is expected to be, in the worst case,
exponential in \(H\) (see~\cite{alliotschiex2002ia&it}).

Since the Monte carlo tree is a stochastic method, one must wait for a
satisfactorily converging solution rather than the exact solution. It has
however been proven in~\cite{kocsis2006bandit} that the bias of the expected
payoff tends to zero.


\section{Model}

In this section, we discuss the model established to approach this configuration
problem. First we defined a structure for a controled sector and all possible
transitions through time. Then a workload model is defined. And finally we
determined a cost per partition and a cost function aimed to be minimized.

\subsection{State}

\subsubsection{Time step}
Since the overall goal is to compute a temporal sequence of partitions over a
day, the day has to be sampled. This sampling in represented as the temporal
difference between a node and its children in the trees mentioned in the
previous section.

\subsubsection{Partitions}\label{ssec:partitions}

In the configuration problem, the airspace needs to be divided into sectors. Each
sector represents an area controlled by two controllers and is composed of
one or more elementary modules. A partition $P$ is a set of
sectors covering all the airspace.

A sector is a group of elementary modules, but in practice only a collection
of sectors are allowed in this model. This collection is referred as the context.
This restriction reflects the fact the more complex the shape is, the harder it
is to manage.

\subsubsection{Transitions}\label{sssec:transitions}

During the day, and with the evolution of the trafic, the workload (rigorously
defined in~\ref{sub:workload}) vary. To help controllers to maintain a
homogeneous level of workload, the airspace partitioning needs to be adapted
through a transition from an inital partition to a target partition.
This maneuver requires either coordination or the opening of a new position
and hence increases controller's workload.
This is the reason why a full reconfiguration isn't feasible, and
only a subset of all available transitions can be operated.

In the model considered here, three transistions are possible namely a merge,
a transfer
or a split. For an airspace composed of three modules $A$, $B$, and $C$,
those actions represent:
\begin{itemize}
  \item merge: $\{\{A, B\}, \{C\}\} \quad \rightarrow \quad \{\{A, B, C\}\}$
  \item split: $\{\{A, B, C\}\} \quad \rightarrow \quad \{\{A, B\}, \{C\}\}$
  \item transfer: $\{\{A, B\}, \{C\}\} \quad \rightarrow \quad \{\{A\}, \{B, C\}\}$
\end{itemize}

TODO : meilleure explication des transitions?

Each transition is composed of at most one merge, split or tranfer; more would
result in too complex reconfigurations.

\subsection{Workload}\label{sub:workload}

Let us now precise the model established to evaluate a workload metric. The
workload depends on external criteria such as sector and trafic complexity
or humain factors (e.g. controller health or stress). In the model assumed here,
the workload felt by a controller is directly and only related to the trafic
complexity.

The simplest approch considers only the number of aircraft per sector $N_\text{aircraft}$. We
defined two arbitary thresholds, namely $th_\text{low}$ and $th_\text{high}$, defining
three zones where the workload is low (resp. normal and high) if $N_\text{aircraft} < th_\text{low}$
(resp. $th_\text{low} < N_\text{aircraft} < th_\text{high}$ and $th_\text{high} < N_\text{aircraft}$).
Those workload levels are translated to probabilities $p_\text{low}$, $p_\text{normal}$ and
$p_\text{high}$, where $p_\text{low}(S)$ is the probability that the sector $S$ is underloaded
(resp. balanced and overloaded). In short, for a sector $S$ at time $t$ and $N_\text{aircraft}$:
\begin{equation}
  \begin{aligned}
    p_\text{low}^{S, t} &= \mathbb{1}_{[0, th_\text{low}]}(N_\text{aircraft}) \\
    p_\text{normal}^{S, t} &= \mathbb{1}_{[th_\text{low}, th_\text{high}]}(N_\text{aircraft})\\
    p_\text{high}^{S, t} &= \mathbb{1}_{[th_\text{low}, \infty[}(N_\text{aircraft})
  \end{aligned}
\end{equation}
where $\mathbb{1}$ is the indicator function defined by:
\begin{equation}
  \mathbb{1}_{I}(x) =
  \begin{cases}
    1 & \text{if\,} \quad x \in I\\
    0 & \text{otherwise}
  \end{cases}
\end{equation}

This expression of the workload, expressed in term of probabilities, allow us to
use a more complex model for the workload such as a neural network
(see~\cite{gianazza2010forecasting}). This method learns the probabilities $p_\text{low}$,
$p_\text{normal}$ and $p_\text{high}$ based on parameters including trafic complexity and
the complexity of the sector (e.g. airspace volume).

\subsection{Partition cost and cost function}

\subsubsection{Partition cost}

In order to evaluate a given partition $P$ at time $t$, a cost $C(P, t)$ needs
to be defined. In this paper, this cost depends on the workload in each the
sector. The definitions given in~\cite{ferrari2017} are used to represent a high
(respectively normal and low) cost for partition \(P\):
\begin{equation}
  \begin{aligned}
    c_+(P, t) &= \sum_{S \in P_t} \delta_{h}(S, t) \cdot p_\text{high}^{S, t} \cdot |S|^2\\
    c_=(P, t) &= \left(
    \sum_{S \in P_t} \delta_{n}(S, t) \cdot p_{norm}^{S} \cdot |S|^{-2}
    \right)^{-1}\\
    c_-(P, t) &= \sum_{S \in P_t} \delta_{l}(S, t) \cdot p_\text{low}^{S, t} \cdot |S|^{-2}
  \end{aligned}
\end{equation}
with $\delta_{h}(P, t)$ (resp. $\delta_{n}(P_t)$ and $\delta_{l}(P_t)$) equals 1
if the probability $p_\text{high}$ (resp. $p_\text{normal}$ and $p_\text{low}$) is superior to
the two others, and 0 otherwise.

It is now possible to assign a cost to each partition. This cost is linear
regarding $c_+$, $c_=$, $c_-$ and $n$ (cardinal of the partition $P$). The
partition cost is defined as follows:
\begin{equation}
  C(P, t) = \alpha c_+ + \beta c_= + \gamma c_- +\lambda n
\end{equation}

The parameters $\alpha$, $\beta$, $\gamma$ and $\lambda$ (all positive)
determine a priority on which parameter to optimize. For instance, a high
value $\alpha$ help to
minimize $c_+$, hence the overall number of sectors with too much trafic.
In a real application, it maybe interesting to order those parameters as
follow: $\alpha > \gamma > \beta > \lambda$.

\subsubsection{Transition cost}

In an operational context, each reconfiguration increases the workload for
controllers. This needs to be considered via the definition of a transition
cost.
A transition is the difference of two partitions separated by only on time step.
The transition cost is then
\begin{equation}
  C_{tr}(P_1, P_2) =
  \begin{cases}
    0 & \text{if} \quad P_1 = P_2\\
    1 & \text{otherwise}
  \end{cases}
\end{equation}

\subsubsection{Objective function}

Having defined a cost for partitions and transitions, it is now possible to
aggregate everything in order to build a cost function over an entire
path. For a path $\pi = [P_0, \dots, P_n]$ with a time from $t_0$ to $t_n$,
the cost function is given by:
\begin{equation}
  \begin{split}
    f(\pi) = C(P_0, t_0) + \sum_{i = 1}^{n} [C(P_i, t_i) +\\
    \theta \cdot C_{tr}(P_{i-1}, P_i)]
  \end{split}
\end{equation}

with $\theta > 0$ a parameter to determine.
This is the immediate function to minimize in the A$^*$ algorithm.

The Monte Carlo Tree search algorithm maximizes an objective function. This function
can be interpreted as the reward of a path.
Given the loss function defined previously, the target function can be
constructed as:
\begin{equation}
  Q(\pi) = \frac{1}{f(\pi)}
\end{equation}


\subsection{Heuristic}
To use effectively the A\(^*\) algorithm, a heuristic is needed. Using the null
heuristic (\(\forall u \in \mathcal{N}, h(u) = 0\)) revealed to be inefficient
considering the branching factor. To build a minimal heuristic, the limitations
introduced in~\ref{sssec:transitions} are not considered, neither those associated
to the previous partition (split, merge or transfer). This allows to generate
the sequence of the best partitions among all possible at each time step.

\section{Results}

TODO

\bibliography{article}
\bibliographystyle{plain}
\end{document}
