\documentclass[oneside,twocolumn]{article}

\usepackage{fontspec}
\usepackage{polyglossia}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{unicode-math}
\usepackage{amsmath,amsthm,stmaryrd}
\usepackage{algorithm,algpseudocode}
\usepackage{paralist}

\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\first}{first}
\DeclareMathOperator{\state}{state}


%\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry}
%\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption}
%\usepackage{booktabs}
%
%\usepackage{lettrine}
%
%\usepackage{enumitem}
%\setlist[itemize]{noitemsep}
%
%\usepackage{abstract}
%% Set the "Abstract" text to bold
%\renewcommand{\abstractnamefont}{\normalfont\bfseries}
%% Set the abstract itself to small italic text
%\renewcommand{\abstracttextfont}{\normalfont\small\itshape}
%
%% Allows customization of titles
%\usepackage{titlesec}
%
%% Headers and footers
%\usepackage{fancyhdr}
%% All pages have headers and footers
%\pagestyle{fancy}
%% Blank out the default header
%% \fancyhead{}
%% Blank out the default footer
%\fancyfoot{}
%% Custom header text
%% \fancyhead[C]{Running title $\bullet$ May 2016 $\bullet$ Vol. XXI, No. 1}
%% Custom footer text
%\fancyfoot[RO,LE]{\thepage}
%\usepackage{titling} % Customizing the title section

\title{Airspace configuration decision based on Monte-Carlo tree search}
\author{Gabriel~Hondet, Beno\^{\i}t Viry}
\date{\today}
\pagestyle{headings}

%-----------------------------------------------------------------------------
%	TITLE SECTION
%-----------------------------------------------------------------------------

%% Move the title up
%\setlength{\droptitle}{-4\baselineskip}
%% Article title formatting
%\pretitle{\begin{center}\Huge\bfseries}
%% Article title closing formatting
%  \posttitle{\end{center}}

%\renewcommand{\maketitlehookd}{%
%  \begin{abstract}
%
%  \end{abstract}
%}

%-----------------------------------------------------------------------------
\begin{document}

\maketitle

\begin{abstract}
  A nice abstract
\end{abstract}


\section*{Notations}
\begin{compactitem}
  \item $m$: elementary module;
  \item $S$: sector control position, group of modules;
  \item $P$: partition of the airspace, group of sectors;
  \item $t$: current time;
  \item $C(P, t)$: cost of a given partition $P$ at time $t$;
  \item \(\mathcal{S}\): the set of available states;
  \item \(\mathcal{A}\): the set of all possible actions;
  \item \(\mathcal{A}(s)\): the available actions from a state \(s\);
  \item $s$: state;
  \item \(f \colon \mathcal{S} \times \mathcal{A} \to \mathcal{S}\):
    transition function giving the resulting states of action \(a\) executed
    from a state \(s\).
  \item $h \colon \mathcal{S} \to \mathbb{R}^+$: heuristic estimating the cost
    from a state \(s \in \mathcal{S}\) to a final state;
  \item \(\mathcal{N}\): the set of nodes
  \item \(u, v \in \mathcal{N}^2\): nodes
  \item \(Q \colon \mathcal{N} \to \mathbb{R}^+\): the reward expectancy of a
    node;
  \item \(N \colon \mathcal{N} \to \mathbb{N}\): number of simulations running
    through or from a node;
  \item \(\first(\ell)\): returns the first element of \(\ell\).
\end{compactitem}

\section{Introduction}
The airspace is divided into sectors, themselves divided into elementary
modules. Each sector is managed by a controller working position composed of two
controllers.
During the day, sectors are split and merged to be able to
manage the varying traffic. Splitting creates smaller sectors and is therefore
used when traffic gets too dense. On the opposite, merging sectors allows fewer
controllers to manage the same airspace, and is therefore used when traffic
becomes sparse.

Currently, configuration is mainly decided on the fly by chief officer (TODO).
This decision is based on the actual workload on each position. This intuitive
approach does not take into account future traffic. This papers aims at
providing a method offering a smoother workload during the day.

Several methods have been considered to solve the dynamic airspace configuration
problem, for instance via genetic algorithms in~\cite{sergeeva2017dynamic},
constraint local search in~\cite{jagare2013airspace}, integer linear
programming in~\cite{treimuth2016branch} or dynamic programming
in~\cite{bloem2010dynamic}.

As seen in~\cite{treimuth2016branch}
or~\cite{sergeeva2017dynamic}, a temporal sequence of configurations will be
provided. Two costs will be considered to create the sequence, namely the cost
associated to each configuration and transition. The former is based on the
workload estimated for one sector given a neural network
(see~\cite{gianazza2010forecasting}).

The sequence of configurations will be represented as a tree. The resulting
sequence will therefore be a path from the root to a leaf of this tree. This
problem is highly combinatorial (partitioning of the airspace). Knowing that a
sochastic tree search algorithm has been honing from a good
player~\cite{gelly2012grand} to the best one with AlphaGo on one of the most
highly combinatorial game wich is the game of Go entices us to use one for this
problem. The Monte Carlo tree search~\cite{browne2012survey} algorithm will be
used to fullfill this task.



\section{Previous related works}
\label{sec:previous_related_works}

The dynamic airspace configuration problem requires a model of the airspace. As
done in~\cite{sergeeva2017dynamic} or~\cite{treimuth2016branch} the airspace
is modelled via a graph. In those graphs, vertices represent elementary modules
and an edge links two adjacent modules. In~\cite{treimuth2016branch}, to be
able to produce a sequence of configurations, the graph is time dependent.
An other way to model the problem is to use a constrained set of
configurations as in~\cite{gianazza2010forecasting} and~\cite{bloem2010dynamic}.
This way any configuration will match specified requirements, which can be
qualified hard constraints.

In most cases the cost of a configuration is based on the workload. Each
approach seems to give their own representation of the workload. For instance,
~\cite{bedouet2016towards} determined workload density proportionally to the time
spent by aircraft in each sector. A simpler version~\cite{sergeeva2017dynamic}
only uses the number of aircraft. On the other hand, more complex methods,
involving many more inputs are also available. For
instance,~\cite{gianazza2010forecasting} used several indicators, such as sector
volume, or vertical incoming flows in the next 15 and 60 minutes. Those
indicators ease the training of a neural network forecasting the workload.

Other soft constraints appear to be relevant to have a better model of
the problem. For instance in~\cite{sergeeva2017dynamic}
and~\cite{bedouet2016towards} a
coordination cost is defined. It represents the surplus of work added by
flights travelling from one sector to an other. The shape of the
resulting sector is considered, as the simpler is
the shape, the easier it is to manage. Complex shapes are therefore avoided,
thanks to the notion of compactness in~\cite{jagare2013airspace} and balconies
in~\cite{sergeeva2017dynamic}. To smooth the transition between two
configurations, the work associated with the reallocation of one or more modules
is evaluated. This can be used in a cost function aimed to be minimised
(in~\cite{bedouet2016towards}).

\section{Algorithm}

The task of building an optimal sequence of partitions (lowering
as much as possible the workload of each controller) is fulfilled by a
stochastic tree search method, namely the Monte Carlo tree search. To assess the
exactness of the results, an exact method (here A\(^*\)) is used.

\subsection{Monte Carlo tree search}
\subsubsection{Overview}
Monte-Carlo is a best-first search method using stochastic simulations. The
algorithm actually uses two trees, an underlying tree associated to the model
(e.g.\ a game tree) and a search tree. The latter is built incrementally by the
algorithm the following way, at each step, starting from the root, the most
promising nodes towards the bottom of the tree are selected. Once a leaf of the
search tree is reached, a new node coming from the model tree is added to the
leaf. A simulation is then run from this newly added node to evaluate the
outcome of a path starting from it. The result of the simulation is eventually
backpropagated to the consecutive parents of the new node.

The above mentioned steps are denoted
\begin{compactenum}
\item selection (or tree walk): choosing successively most promising nodes,
\item expansion: adding new nodes to the search tree,
\item simulation (or random walk): choosing quickly actions from the model
  tree,
\item backpropagation (or backup): applying the result of the simulation to
  the search tree.
\end{compactenum}
Those phases are repeated until a stopping criterium (e.g.\ memory or time) is
reached, resulting in algorithm~\ref{alg:gen_mcts} where the tree policy
aggregates phases 1 and 2 to create a new node of the search tree and the
default policy gives an evaluation of the newly added node.
\begin{algorithm}
  \caption{General MCTS~\cite{browne2012survey}}\label{alg:gen_mcts}
  \begin{algorithmic}
    \Procedure{MctsSearchTree}{$v_0$}
    \While{within computational budget}
    \State{} \([v_0, \dots, v_n] \gets\) \Call{TreePolicy}{$v_0$}
    \State{} \(\Delta \gets\) \Call{DefaultPolicy}{$v_n$}
    \State{} \Call{Backup}{$[v_0, \dots, v_n]$, $\Delta$}
    \EndWhile{}
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

\subsubsection{Extending the search tree}
\paragraph{Selection (algorithm~\ref{alg:tree_pol})}
The aim of the selection is to choose from a set of actions, the most promising
one\footnote{i.e.\ possibly leading to the best evaluation} according to a
\emph{tree policy}. This type of problem is addressed by bandits methods where
a multi armed bandit aims to always activate the slot machine giving the highest
reward.

The bandit problem is applied to MCTS via the Upper Confidence Tree algorithm.
It uses the UCB (Upper Confidence Bound) as tree policy (introduced
in~\cite{kocsis2006bandit}). Let \(v\) be the node from which an action must be
selected to go deeper in the tree, \(a\) an action available from \(v\),
\(\mu_{v,a}\) the expected outcome from the node obtained by applying action
\(a\) on \(v\), \(T_v\) the number of simulations carried out from node \(v\)
(which includes any simulation from nodes in any subtree of \(v\)) and
\(T_{v,a}\) the number of simulations carried out from the node resulting from
the action \(a\) applied to node \(v\), \(\beta\) a constant. The selected node
is thus the one maximising the \emph{UCB1} equation
\begin{equation}
  \mu_{v,a} + 2 \beta \sqrt{\frac{2 \log T_v}{T_{v,a}}}
\end{equation}

While the previous equation is well suited for two players games, it can be
tweaked to improve its efficience in one player games or sequencing problems. An
alternative using the standard deviation of the outcome of the simulations is
proposed in~\cite{sebag2010fuse} called the \emph{UCB1-tuned} equation
\begin{equation}
  \mu_{v,a} +
  \sqrt{%
    \frac{\beta\log T_v}{t_{v,a}}
    \min\left( \frac{1}{4}, \sigma^2_{v,a} +
    \sqrt{%
      \frac{2 \log T_v}{T_{v,a}}
    }\right)
  }
\end{equation}
\begin{algorithm}
  \caption{UCT algorithm}\label{alg:tree_pol}
  \begin{algorithmic}
    \Function{TreePolicy}{$\pi$}
    \State{}\(v \gets \first(\pi)\)
    \If{$v$ is terminal}
    \State{}\Return{$\pi$}
    \Else{}
    \If{$v$ is not fully expanded}
    \State{}\Return{\Call{Expand}{$v$} $\cup \pi$}
    \Else{}
    \State{}$f \gets$ \Call{BestChild}{$v$}
    \State{}\Return{%
      \Call{TreePolicy}{$f \cup \pi$}
    }
    \EndIf{}
    \EndIf{}
    \EndFunction{}
  \end{algorithmic}
  \begin{algorithmic}
    \Function{BestChild}{$v$}
    \State{}\Return{$\argmax\{\Call{UCB}{v'} | v' \text{\,children of\,} v \}$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\paragraph{Expansion (algorithm~\ref{alg:expansion})}
The above step is carried out only if, considering a node \(v\), a simulation
has been run through each child available from \(v\). In the case where one or
more children haven't been explored yet, one of the unexplored children is
chosen and a simulation is started from it.
\begin{algorithm}
  \caption{Expansion}\label{alg:expansion}
  \begin{algorithmic}
    \Function{Expand}{$v$}
    \State{}$\ell \gets \{ v | v \text{\,children of\,} u, N(v) = 0 \}$
    \State{}\Return{random element from $\ell$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\subsubsection{Simulation and backpropagation}
\paragraph{Simulation}
Once a node has been expanded, random nodes are chosen successively until a
terminal state is found. The cost of the resulting path, from the root to the
node is then evaluated and backpropagated to all the ancestors of the expanded
node.

\subparagraph{Heuristic} One might want to bias the randomness while choosing
nodes. This would imply using a heuristic which has to be able to discriminate
a node between its siblings.

\paragraph{Backpropagation}
The backpropagation consists in updating the values required to carry out the
tree policy. The values must be updated incrementally since the backpropagation
function has the current value of the parameters and the result of the
simulation as parameters. Thus, for UCB1 equation, the expected reward (mean)
and the total count are updated this way
\begin{algorithm}
  \caption{UCB1 backpropagation}
  \begin{algorithmic}
    \Procedure{Backpropagate}{$v$, $r$}
    \State{}\(\delta \gets\ r - \mu_v\)
    \State{}\(Q(v) \gets Q(v) + \frac{\delta}{N(v) + 1}\)
    \State{}\(N(v) \gets N(v) + 1\)
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

For the UCB1-tuned, the standard deviation has to be computed. It results in
algorithm~\ref{alg:backpropagate-tuned} which introduces the value \(m_2(v)\)
associated to a node \(v\) to compute the standard deviation via the formula
\begin{equation}
  \sigma^2_v = \frac{m_2(v)}{N(v)}.
\end{equation}
\begin{algorithm}
  \caption{UCB1-tuned backpropagation}\label{alg:backpropagate-tuned}
  \begin{algorithmic}
    \Procedure{Backpropagate}{$v, r$}
    \State{}\(\delta \gets r - Q(v)\)
    \State{}\(Q(v) \gets Q(v) + \frac{\delta}{N(v) + 1}\)
    \State{}\(\delta' \gets r - Q(v)\)
    \State{}\(m_2(v) \gets m_2(v) + \delta \delta'\)
    \State{}\(N(v) \gets N(v) + 1\)
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}


\subsection{Sequence building}
\subsubsection{Node selection}\label{sssec:node_selection}
The building of the final sequence of actions differs from the selection on the
aim, the selection chooses the most promising actions while the final sequence
must be composed of the best. This means that the final path build won't use the
UCB equation. Chaslot \textit{et al.}~\cite{browne2012survey} propose several
methods to select nodes,
\begin{compactitem}
  \item max-child: select the child with highest reward;
  \item robust child: select the most visited root child;
  \item secure child: select the child maximising a lower confidence bound.
\end{compactitem}

\subsubsection{Iterative pathfinding}
The path is built iteratively by calling successive Monte Carlo tree searches.
Say an MCTS has been called on a node \(u\). Once a stopping criterium is
matched, a node \(v\) among the ones reachable from \(u\) is selected via one of
the previously mentioned policies. Then an mcts is called back with node \(u\)
as the root node. The path is composed of the successive roots. The algorithm is
described at~\ref{alg:path_building}.
\begin{algorithm}
  \caption{%
    Path building. The {\sc NextNode} (here max-child) function is one among
    those in~\ref{sssec:node_selection}.
  }\label{alg:path_building}
  \begin{algorithmic}
    \Function{MctsSearch}{$u_0, n$}
    \State{}\(u \gets u_0\)
    \State{}\(\pi \gets \{u\}\)
    \For{$i = 1$ to $n$}
      \State{}\Call{MctsSearchTree}{$u$}
      \State{}\(u \gets\)\Call{NextNode}{$u$}
      \State{}\(\pi \gets \pi \cup \{u\}\)
    \EndFor{}
    \State{}\Return{$\pi$}
    \EndFunction{}
    \Function{NextNode}{$u$}
    \State{}\Return{$\argmax\{Q(v) | v \text{\,children of\,} u\}$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}
\subsection{A\(^*\)}
To evaluate the exactness of the paths given by the MCTS algoithm, the A\(^*\)
algorithm is used. A\(^*\) is an exact depth first search pathfinding algorithm
which uses a heuristic function to guide its search. The algorithm is given
in~\ref{alg:astar} where \(u_0\) is the initial state, \(T\) the set of termial
nodes, \(h\) a heuristic function estimating the cost from a state \(u\) given
as argument to a final state, \(k \colon \mathcal{S}^2 \to \mathbb{R}\). The
function \(\mathup{first(G)}\) returns the first element of \(G\) and
\(f\mathup{-insert}(G, v)\) inserts \(v\) in \(G\) ordering first by \(f\)
increasing then by \(g\) decreasing.
\begin{algorithm}
  \caption{A\(^*\) algorithm~\cite{alliotschiex2002ia&it}}\label{alg:astar}
  \begin{algorithmic}
    \Procedure{A$^*$}{$u_0$}
    \State{}\(G \gets u_0; D \gets \emptyset; g(u_0) \gets 0; f(u_0) \gets 0\)
    \State{}\(\mathup{father}(u_0) \gets \emptyset\)
    \While{$G \neq \emptyset$}
    \State{}\(u \gets \mathup{first}(G); G \gets G \backslash \{u\}\)
    \State{}\(D \gets D \cup \{u\}\)
    \If{$u \in T$}
    \State{}\Return{father}
    \EndIf{}
    \For{$v$ in childen of $u$}
    \If{$v \notin D \cup G$ or $[g(v) > g(u) + k(u, v)]$}
    \State{}\(g(v) \gets g(u) + k(u, v)\)
    \State{}\(f(v) \gets g(v) + h(v)\)
    \State{}\(\mathup{father}(v) \gets u\)
    \State{}\(f\mathup{-insert}(G, v)\)
    \EndIf{}
    \EndFor{}
    \EndWhile{}
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}
\section{Model}

In this section, we discuss the model established to approach this configuration
problem. First we defined a structure for a controled sector and all possible
transitions through time. Then a workload model is defined. And finally we
determined a cost per partition and a cost function aimed to be minimized.

\subsection{State}



\subsection{workload}

$p_{low}$
$p_{normal}$
$p_{high}$

\subsection{Partition cost and cost function}

\subsubsection{Partition cost}

In order to evaluate a given partition $P$ at time $t$, a cost $C(P, t)$ needs
to be defined. This cost depend on the workload in each the sector. We give the
following definitions~\cite{ferrari2017} to represent a high
(respectively normal and low) cost for the partition:
\begin{itemize}
  \item $c_+(P, t) = \sum_{S \in P_t} \delta_{h}(S, t) * p_{high}^{S, t} * |S|^2$
  \item $c_=(P, t) = 1 / (\sum_{S \in P_t} \delta_{n}(S, t) * p_{norm}^{S} * |S|^{-2}$)
  \item $c_-(P, t) = \sum_{S \in P_t} \delta_{l}(S, t) * p_{low}^{S, t} * |S|^{-2}$
\end{itemize}
with $\delta_{h}(P, t)$ (resp. $\delta_{n}(P_t)$ and $\delta_{l}(P_t)$) equal 1
if the probability $p_{high}$ (resp. $p_{normal}$ and $p_{low}$) is superior to
the two others, and 0 otherwise.

It is now possible to assign a cost to each partition. This cost is linear
regarding $c_+$, $c_=$, $c_-$ and $n$ (cardinal of the partition $P$). The
partition cost is defined as follow:
\begin{equation}
C(P, t) = \alpha c_+ + \beta c_= + \gamma c_- +\lambda n  
\end{equation}

The parameters $\alpha$, $\beta$, $\gamma$ and $\lambda$ (all positive)
determine a priority on which parameter to optimize. For instance, a high
value $\alpha$ help to
minimize $c_+$, hence the overall number of sectors with too much tafic.
In a real application, it maybe interesting to order those parmaeters as
follow : $\alpha > \gamma > \beta > \lambda$.

\subsubsection{Transition cost}

In an operational context, each reconfiguration raise the workload for
controllers. This trend needs to be considered and a transition cost needs to
be defined for this matter. A transition is (TODO), and the transition cost is
then:
\begin{equation}
  C_{tr}(P_1, P_2) =
\left\{
\begin{array}{l}
    0 \qquad if \qquad P_1 = P_2 \\
    1 \qquad otherwise
\end{array}
\right.
\end{equation}

\subsubsection{Objective function}

With a cost defined for partition and transition, it is now possible to
aggregate everything in order to build a cost function over an entire
path. For a path ($path = [P_0, ..., P_n]$) with a time from $t_0$ to $t_n$,
the cost function is given by:
\begin{equation}
  \begin{split}
  f(path) = C(P_0, t_0) + \sum_{i = 1}^{n} [C(P_i, t_i) +\\ \theta \times C_{tr}(P_{i-1}, P_i)]   
  \end{split}
\end{equation}

with $\theta > 0$ a parameter to determine.
This is the imediate function to minimize in the A$^*$ algorithm.

The Monte Carlo Tree search algorithm maximize a objective function. This function
represent a potential reward over a path, i.e. a list of partitions over time.
Given the loss function defined previously, the target function can be
construct as:
\begin{equation}
  \psi(path) = \frac{1}{f(path)}
\end{equation}






\bibliography{article}
\bibliographystyle{plain}
\end{document}
