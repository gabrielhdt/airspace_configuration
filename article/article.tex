\documentclass[oneside,twocolumn]{article}

\usepackage{fontspec}
\usepackage{polyglossia}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{unicode-math}
\usepackage{amsmath,amsthm,stmaryrd}
\usepackage{algorithm,algpseudocode}
\usepackage{paralist}
\usepackage{titlesec}
\usepackage{tikz,pgfplots}
\usepackage{array,tabulary,booktabs}

\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\first}{first}
\DeclareMathOperator{\state}{state}

% Headings customisation
\titleformat*{\section}{\Large\scshape\center}
\renewcommand{\thesection}{\Roman{section}}
\renewcommand{\thesubsection}{\Roman{section}.\Alph{subsection}}


\title{Monte Carlo tree search compared to A\(^*\) in airspace configuration
decision problem}
\author{Gabriel~Hondet, Beno\^{\i}t Viry}
\date{\today}
\pagestyle{headings}

\begin{document}

\maketitle

\begin{abstract}
  Dynamic airspace configuration is a highly combinatorial partitioning
  problem. Since exact methods tend to be overwhelmed by the complexity of such
  problems, a stochastic approach is here considered. This paper presents the
  Monte Carlo tree search algorithm using UCT search and adapted to one
  player games. The application of the algorithm to the airspace partitioning
  problem is
  then detailed. Finally the Monte Carlo tree search is compared to the A\(^*\).
\end{abstract}


\section*{Notations}
\begin{compactitem}
  \item $m$: elementary module;
  \item $S$: air traffic control sector, group of modules;
  \item $P$: partition of the airspace, group of sectors;
  \item $t$: current time;
  \item $C(P, t)$: cost of a given partition $P$ at time $t$;
  \item \(C_{tr}(P_1, P_2)\): cost of transition between partitions \(P_1\) and
    \(P_2\);
  \item \(\pi = [P_1, \dots, P_n]\): a sequence of partitions (called \emph{path}
      in the tree search algorithms);
  \item \(f(\pi)\): cost associated to sequence of partitions \(\pi\);
  \item \(\mathcal{N}\): the set of nodes;
  \item \(u, v \in \mathcal{N}^2\): nodes
  \item $h \colon \mathcal{N} \to \mathbb{R}^+$: heuristic estimating the cost
    from a node \(u\) to a final node;
  \item \(\mu_v\): mean value of outcomes of simulations run through or from a
    node \(v\);
  \item \(T_v\): number of simulations run through or from a node \(v\);
  \item \(\first(\ell)\): returns the first element of \(\ell\).
\end{compactitem}

\section{Introduction}
The airspace is divided into sectors, themselves divided into elementary
modules. Each sector is managed by a controller working position composed of two
controllers.
During the day, sectors are split and merged to be able to
manage the varying traffic. Splitting creates smaller sectors and is therefore
used when traffic gets too dense. On the opposite, merging sectors allows fewer
controllers to manage the same airspace, and is therefore used when traffic
becomes sparse.

Currently, configuration is mainly decided on the fly by the chief officer.
This decision is based on the actual workload on each position. In this
approach, future workload estimation is based on the controller's feelings and
it therefore lacks a workload prediction tool.
This papers aims at providing a method predicting the airspace configuration.

Several methods have been considered to solve the dynamic airspace configuration
problem, for instance via genetic algorithms in~\cite{sergeeva2017dynamic},
constraint local search in~\cite{jagare2013airspace}, integer linear
programming in~\cite{treimuth2016branch} or dynamic programming
in~\cite{bloem2010dynamic}.

In this paper, a temporal sequence of configurations is considered, as
in~\cite{treimuth2016branch} or~\cite{sergeeva2017dynamic}.
Two costs are considered to create the sequence, namely the cost
associated to each configuration and a transition cost. The former is based on
the workload estimated for one sector given by a simple model. More complex
models might be used such as a neural network
(see~\cite{gianazza2010forecasting}).

The sequence of configurations is extracted from a tree. The resulting
sequence will therefore be a path from the root to a leaf of this tree. This
problem is highly combinatorial (partitioning of the airspace). Since stochastic
tree search algorithms, combined with deep neural networks have proved
themselves worthy by outranking the best human player of one of the most highly
combinatorial game which is the game of Go, the Monte Carlo tree
search~\cite{browne2012survey} algorithm is used in this paper to fulfill the
previously mentioned task.



\section{Previous related works}\label{sec:previous_related_works}

The dynamic airspace configuration problem requires a model of the airspace.
In~\cite{sergeeva2017dynamic} or~\cite{treimuth2016branch} the airspace
is modelled via a graph. In those graphs, vertices represent elementary modules
and an edge links two adjacent modules. In~\cite{treimuth2016branch}, to be
able to produce a sequence of configurations, the graph is time dependent.
An other way to model the problem is to use a constrained set of
configurations as in~\cite{bloem2010dynamic}.
This way any configuration will match specified requirements, which can be
qualified as hard constraints.

In most cases the cost of a configuration is based on the workload. Each
approach seems to give their own representation of the workload. For instance,
\cite{bedouet2016towards} determined workload density proportionally to the time
spent by aircraft in each sector. A simpler version~\cite{sergeeva2017dynamic}
only uses the number of aircraft. On the other hand, more complex methods,
involving many more inputs are also available. For
instance,~\cite{gianazza2010forecasting} used several indicators, such as sector
volume, or vertical incoming flows in the next 15 and 60 minutes. Those
indicators as inputs to a neural network forecasting the workload.

Other soft constraints appear to be relevant to have a better model of
the problem. For instance in~\cite{sergeeva2017dynamic}
and~\cite{bedouet2016towards} a
coordination cost is defined. It represents the surplus of work added by
flights travelling from one sector to an other. The shape of the
resulting sector is considered, as the simpler is
the shape, the easier it is to manage. Complex shapes are therefore avoided,
thanks to the notion of compactness in~\cite{jagare2013airspace} and balconies
in~\cite{sergeeva2017dynamic}. To smooth the transition between two
configurations, the work associated with the reallocation of one or more modules
is evaluated. This transition cost is included in the cost function being
minimised (in~\cite{bedouet2016towards}).

In this paper, each partition scheme is based upon the number of aircraft in
each
elementary module and the cost of transition from the previous partitioning.
The set of available parititions can be computed from the set of elementary
modules and a context which contains all available ATC sectors.

The Monte Carlo tree search algorithm has been widely used in two-player games.
Only three years after its apparition in 1990, Br\"ugmann applies it to the Go
game in~\cite{brugmann1993mcgo}. While the Monte-Carlo tree search is still
extensively used in two-player games (and especially the Go game), its
adaptation to one player game has been worked on. Auer \textit{et al.} propose
an
upper confidence bound formula in~\cite{sebag2010fuse} which appears to be more
efficient for one player games. The introduced formula uses the standard
deviation of the outcome of the simulations.
The latter article also uses the rapid
action value estimation (RAVE) technique to quicken the convergence of the
algorithm. RAVE uses the ``all moves as first'' heuristic, in which all
moves\footnote{a move is informally considered as a decision taken regarding
which state to choose while descending the search tree}
seen during simulations are considered as a first move. This allows the
algorithm to update more statistics in one simulation. Gelly \textit{et al.} use
in~\cite{gelly2012grand} the RAVE technique coupled with several heuristics. The
heuristics bias the initialisaton of a node in the search tree, pre filling its
statistics using prior knowledge of the problem.

\section{Algorithm}

The task of building an optimal sequence of partitions (lowering
as much as possible the workload of each controller) is fulfilled by a
stochastic tree search method, namely the Monte Carlo tree search. To assess the
quality of the results, an exact method (here A\(^*\)) is used.

\subsection{Monte Carlo tree search}
\subsubsection{Overview}\label{sssec:overview}
Monte-Carlo is a best-first search method using stochastic simulations. The
algorithm is based on the computation of the reward expectancy of paths which
is estimated through Monte-Carlo simulations.
The
algorithm actually uses two trees, an underlying tree associated to the model
(e.g.\ a game tree) and a search tree. The latter is built incrementally, each
step being composed of four phases, namely
\begin{compactenum}
\item\label{it:selection} selection (or tree walk): choosing successively
  most promising nodes from the search tree,
\item\label{it:expansion} expansion: adding new nodes to the search tree,
\item simulation (or random walk): choosing successively nodes from the model
  tree, from the expanded node to a leaf,
\item backpropagation (or backup): applying the result of the simulation to
  the previously selected nodes of the search tree (phases~\ref{it:selection}
  and~\ref{it:expansion}).
\end{compactenum}
Those phases are repeated until a stopping criterion (e.g.\ memory or time) is
reached, resulting in algorithm~\ref{alg:gen_mcts} where the tree policy
aggregates phases 1 and 2 to create a new node of the search tree and the
default policy gives an evaluation of the newly added node.
\begin{algorithm}
  \caption{General MCTS~\cite{browne2012survey}}\label{alg:gen_mcts}
  \begin{algorithmic}
    \Procedure{MctsSearchTree}{$v_0$}
    \While{within computational budget}
    \State{}\(\pi \gets\) \Call{TreePolicy}{$v_0$}
    \State{}\(v \gets \first(\pi)\)
    \State{}\(\Delta \gets\) \Call{DefaultPolicy}{$v$}
    \State{}\Call{Backup}{$\pi$, $\Delta$}
    \EndWhile{}
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

\subsubsection{Extending the search tree}
\paragraph{Selection (algorithm~\ref{alg:tree_pol})}
The aim of the selection is to build a path from the root of the search tree
by choosing successively the most
promising\footnote{i.e.\ possibly leading to the best evaluation} node.
Given a node \(u\) that has previously been selected, the
best node --
according to a \emph{tree policy} -- among the children of \(u\) is
chosen.
This type
of problem can be solved by bandits methods.
Those methods consist in, given a bandit in front of several slot machines
(multi armed bandit), deciding which machine will bring the highest reward
knowing
the past results. The objective of bandits methods is thus to maximise the reward
and minimise the regret of not playing the best machine.

The bandit problem has been applied to MCTS via the Upper Confidence Tree
algorithm in~\cite{kocsis2006bandit} using the UCB1 equation~\ref{eq:ucb1}.
Let \(u\) be the node from which a child \(v\) must be selected to go deeper in
the tree, \(T_u\) the number of simulations carried out from node \(u\)
(which includes any simulation from nodes in any subtree of \(u\)) and
\(\beta\) a chosen constant. The selected child \(v\) is the one maximising the
\emph{UCB1} equation
\begin{equation}
  \label{eq:ucb1}
  \mu_v + 2 \beta \sqrt{\frac{2 \log T_u}{T_v}}
\end{equation}

While the previous equation is well suited for two players games, it can be
tweaked to improve its efficiency in one player games or sequencing problems. An
alternative using the standard deviation \(\sigma_v\) of the outcome of the
previous simulations involving node \(v\) is
proposed in~\cite{sebag2010fuse} called the \emph{UCB1-tuned} equation
\begin{equation}\label{eq:ucb1-tuned}
  \mu_v +
  \beta\sqrt{%
    \frac{\log T_u}{T_v}
    \min\left( \frac{1}{4}, \sigma^2_v +
    \sqrt{%
      \frac{2 \log T_u}{T_v}
    }\right)
  }
\end{equation}
\begin{algorithm}
  \caption{UCT algorithm}\label{alg:tree_pol}
  \begin{algorithmic}
    \Function{TreePolicy}{$\pi$}
    \State{}\(v \gets \first(\pi)\)
    \If{$v$ is terminal}
    \State{}\Return{$\pi$}
    \Else{}
    \If{$v$ is not fully expanded}
    \State{}\Return{\Call{Expand}{$v$} $\cup \pi$}
    \Else{}
    \State{}$f \gets$ \Call{BestChild}{$v$}
    \State{}\Return{%
      \Call{TreePolicy}{$f \cup \pi$}
    }
    \EndIf{}
    \EndIf{}
    \EndFunction{}
  \end{algorithmic}
  \begin{algorithmic}
    \Function{BestChild}{$v$}
    \State{}\Return{$\argmax\{\Call{UCB}{v'} | v' \text{\,children of\,} v \}$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\subparagraph{Exploration exploitation trade-off} The constant \(\beta\) answers
to the exploration-exploitation dilemma. In the UCB1 equations~\ref{eq:ucb1}
and~\ref{eq:ucb1-tuned},
the right hand term increases the UCB value of less explored nodes to consider them
as still promising. A high \(\beta\) value will therefore make the algorithm
prone to try unvisited nodes while a low value will consider almost exclusively
the results obtained so far, even if other paths are better but unexplored.

\paragraph{Expansion (algorithm~\ref{alg:expansion})}
If the selected node has one or more unvisited children, the selection stops and
one of them is added to the search tree randomly, the latter being thus expanded
by this new node.
\begin{algorithm}
  \caption{Expansion}\label{alg:expansion}
  \begin{algorithmic}
    \Function{Expand}{$u$}
    \State{}$\ell \gets \{ v | v \text{\,children of\,} u, T_v = 0 \}$
    \State{}\Return{random element from $\ell$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\subsubsection{Simulation and backpropagation}
The two steps described in this paragraph aim to guess the reward that can be
expected from a path including a given node.
\paragraph{Simulation}
Once a node has been expanded, random nodes are chosen successively until a
terminal state is found. The cost of the resulting path, from the root to the
node is then evaluated and backpropagated to all the ancestors of the expanded
node.

\subparagraph{Heuristic} One might want to bias the randomness while choosing
nodes. This would imply using a heuristic which has to be able to discriminate
a node between its siblings.

\paragraph{Backpropagation}
The backpropagation consists in updating the values required to carry out the
tree policy. The values must be updated incrementally since the backpropagation
function has the current value of the parameters and the result of the
simulation as parameters. Thus, for UCB1 equation, the expected reward (mean)
and the total count are updated this way
\begin{algorithm}
  \caption{UCB1 backpropagation}
  \begin{algorithmic}
    \Procedure{Backpropagate}{$u$, $r$}
    \State{}\(\delta \gets r - \mu_u\)
    \State{}\(\mu_u \gets \mu_u + \frac{\delta}{T_u + 1}\)
    \State{}\(T_u \gets T_u + 1\)
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

For the UCB1-tuned, the standard deviation has to be computed. It results in
algorithm~\ref{alg:backpropagate-tuned} which introduces the value \(m_2(u)\)
associated to a node \(u\) to compute the standard deviation via the formula
\begin{equation}
  \sigma^2_u = \frac{m_2(u)}{T_u}.
\end{equation}
\begin{algorithm}
  \caption{UCB1-tuned backpropagation}\label{alg:backpropagate-tuned}
  \begin{algorithmic}
    \Procedure{Backpropagate}{$u, r$}
    \State{}\(\delta \gets r - \mu_u\)
    \State{}\(\mu_u \gets \mu_u + \frac{\delta}{T_u + 1}\)
    \State{}\(\delta' \gets r - \mu_u\)
    \State{}\(m_2(u) \gets m_2(u) + \delta \delta'\)
    \State{}\(T_u \gets T_u + 1\)
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}


\subsection{Sequence building}
Once the stopping criterium mentioned in~\ref{sssec:overview} is matched, the
sequence of states can be extracted from the search tree.

\subsubsection{Choosing nodes}\label{sssec:node_selection}
To build the final sequence, nodes are chosen according to a criterion.
Chaslot \textit{et al.} in~\cite{chaslot2008progstrat} propose several
methods to select nodes,
\begin{compactitem}
  \item max-child: select the child with highest mean reward;
  \item robust child: select the most visited root child;
  \item secure child: select the child maximising a lower confidence bound.
\end{compactitem}

\subsubsection{Iterative pathfinding}
The path is built iteratively by calling successive Monte Carlo tree searches.
Say an MCTS has been called on a node \(u\). Once a stopping criterium is
matched, a node \(v\) among the ones reachable from \(u\) is selected via one of
the previously mentioned policies. Then the MCTS algorithm is called back with
node \(v\)
as the root node. The final path is composed of the successive roots. The
algorithm is described in~\ref{alg:path_building}.
\begin{algorithm}
  \caption{%
    Path building. The {\sc NextNode} (here max-child) function is one among
    those in~\ref{sssec:node_selection}.
  }\label{alg:path_building}
  \begin{algorithmic}
    \Function{MctsSearch}{$u_0, n$}
    \State{}\(u \gets u_0\)
    \State{}\(\pi \gets \{u\}\)
    \For{$i = 1$ to $n$}
      \State{}\Call{MctsSearchTree}{$u$}
      \State{}\(u \gets\)\Call{NextNode}{$u$}
      \State{}\(\pi \gets \pi \cup \{u\}\)
    \EndFor{}
    \State{}\Return{$\pi$}
    \EndFunction{}
    \Function{NextNode}{$u$}
    \State{}\Return{$\argmax\{\mu_v | v \text{\,children of\,} u\}$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}
\subsection{A\(^*\)}
To evaluate the exactness of the paths given by the MCTS algoithm, the A\(^*\)
algorithm is used. A\(^*\) is an exact best first search pathfinding algorithm
which uses a heuristic function to guide its search. The algorithm is given
in~\ref{alg:astar} where \(u_0\) is the initial state, \(T\) the set of terminal
nodes, \(h\) a heuristic function estimating the cost from a state \(u\) given
as argument to a final state, \(k \colon \mathcal{N}^2 \to \mathbb{R}\). The
function \(\first(G)\) returns the first element of \(G\) and
\(f\mathup{-insert}(G, v)\) inserts \(v\) in \(G\) ordering first by \(f\)
increasing then by \(g\) decreasing.
\begin{algorithm}
  \caption{A\(^*\) algorithm~\cite{alliotschiex2002ia&it}}\label{alg:astar}
  \begin{algorithmic}
    \Procedure{A$^*$}{$u_0$}
    \State{}\(G \gets u_0; D \gets \emptyset; g(u_0) \gets 0; f(u_0) \gets 0\)
    \State{}\(\mathup{father}(u_0) \gets \emptyset\)
    \While{$G \neq \emptyset$}
    \State{}\(u \gets \first(G); G \gets G \backslash \{u\}\)
    \State{}\(D \gets D \cup \{u\}\)
    \If{$u \in T$}
    \State{}\Return{father}
    \EndIf{}
    \For{$v$ in childen of $u$}
    \If{$v \notin D \cup G$ or $[g(v) > g(u) + k(u, v)]$}
    \State{}\(g(v) \gets g(u) + k(u, v)\)
    \State{}\(f(v) \gets g(v) + h(v)\)
    \State{}\(\mathup{father}(v) \gets u\)
    \State{}\(f\mathup{-insert}(G, v)\)
    \EndIf{}
    \EndFor{}
    \EndWhile{}
    \EndProcedure{}
  \end{algorithmic}
\end{algorithm}

\paragraph{Heuristic}
To be sure to have the optimal solution, the heuristic \(h\) has to be
\emph{minimal} i.e.\ let \(h^*\) be the optimal heuristic (the one giving the
true distance from a node to a final state), then for any node \(u\), \(h(u)
\leq h^*(u)\).


\subsection{Theoretical performances}\label{ssec:theoretical_performances}
In this paper, a high branching factor problem is considered.

Let \(H\) be the height of the tree, \(K\) the branching factor.
Then, the complexity of the A\(^*\) is expected to be, in the worst case,
exponential in \(H\) (see~\cite{alliotschiex2002ia&it}).

Since the Monte carlo tree is a stochastic method, one must wait for a
satisfactorily converging solution rather than the exact solution. It has
however been proven in~\cite{kocsis2006bandit} that the bias of the expected
payoff tends to zero.


\section{Model}

In this section, we discuss the model established to approach this configuration
problem. First we define a structure for a controlled sector and all possible
transitions through time. Then a workload model is defined. And finally we
define a cost per partition and a cost function aimed to be minimized.

\subsection{State}

\subsubsection{Time step}
Since the overall goal is to compute a temporal sequence of partitions over a
day, the day has to be sampled. In the model tree, a timestep separates a node
from its children. Practically, a timestep is one minute.

\subsubsection{Partitions}\label{ssec:partitions}

In the configuration problem, the airspace needs to be divided into sectors. Each
sector represents an area controlled by two controllers and is composed of
one or more elementary modules. A partition $P$ is a set of
non-overlapping sectors covering all the airspace.

A sector is a group of elementary modules, but in practice only a collection
of sectors are allowed in this model. This collection is referred to as the
context. It is the list of operation ATC sectors actually used in ATC centres.

\subsubsection{Transitions}\label{sssec:transitions}

During the day, and with the evolution of the traffic, the workload (rigorously
defined in~\ref{sub:workload}) varies. To help controllers to maintain a
homogeneous level of workload, the airspace partitioning needs to be adapted
through successive transitions starting from an inital partition.
This maneuver requires either coordination or the opening of a new position
and hence increases controller's workload.
This is the reason why a full reconfiguration isn't feasible, and
only a subset of all available transitions can be operated.

In the model considered here, three transitions are possible namely a merge,
a transfer
or a split. For an airspace composed of three modules $A$, $B$, and $C$,
those actions represent:
\begin{itemize}
  \item merge: $\{\{A, B\}, \{C\}\} \quad \rightarrow \quad \{\{A, B, C\}\}$
  \item split: $\{\{A, B, C\}\} \quad \rightarrow \quad \{\{A, B\}, \{C\}\}$
  \item transfer: $\{\{A, B\}, \{C\}\} \quad \rightarrow \quad \{\{A\}, \{B, C\}\}$
\end{itemize}

Each transition is composed of at most one merge, split or transfer; more would
result in too complex reconfigurations.

\subsubsection*{Tree translation}
In the tree used in the algorithm exposed earlier, each node has an embedded
state. Considering a node \(u\), its children are the elements of the set of
nodes having as states the possible transitions from the state of \(u\). Going
down in the tree by selecting nodes is then equivalent to moving forward through
time, each step in the tree being a time step.

\subsection{Workload}\label{sub:workload}

Let us now precise the model established to evaluate a workload metric. The
workload depends on external criteria such as sector and traffic complexity
or human factors (e.g.\ controller health or stress). In the model assumed here,
the workload felt by a controller is directly and only related to the traffic
complexity.

The simplest approch considers only the number of aircraft per sector $N_\text{aircraft}$. We
define two arbitary thresholds, namely $th_\text{low}$ and $th_\text{high}$, defining
three zones where the workload is low (resp.\ normal and high) if $N_\text{aircraft} < th_\text{low}$
(resp. $th_\text{low} \leq N_\text{aircraft} \leq th_\text{high}$ and $th_\text{high} < N_\text{aircraft}$).
Those workload levels are translated to probabilities $p_\text{low}$, $p_\text{normal}$ and
$p_\text{high}$, where $p_\text{low}(S)$ is the probability that the sector $S$ is underloaded
(resp.\ balanced and overloaded). In short, for a sector $S$ at time $t$ and $N_\text{aircraft}$:
\begin{equation}
  \begin{aligned}
    p_\text{low}^{S, t} &= \mathbb{1}_{[0, th_\text{low}[}(N_\text{aircraft}) \\
    p_\text{normal}^{S, t} &= \mathbb{1}_{[th_\text{low}, th_\text{high}]}(N_\text{aircraft})\\
    p_\text{high}^{S, t} &= \mathbb{1}_{]th_\text{low}, \infty[}(N_\text{aircraft})
  \end{aligned}
\end{equation}
where $\mathbb{1}$ is the indicator function defined by:
\begin{equation}
  \mathbb{1}_{I}(x) =
  \begin{cases}
    1 & \text{if\,} \quad x \in I\\
    0 & \text{otherwise}
  \end{cases}
\end{equation}

This expression of the workload, expressed in terms of probabilities, allows us to
use a more complex model for the workload such as a neural network
(see~\cite{gianazza2010forecasting}). This method learns the probabilities $p_\text{low}$,
$p_\text{normal}$ and $p_\text{high}$ based on parameters including traffic complexity and
the complexity of the sector (e.g.\ airspace volume).

\subsection{Partition cost and cost function}

\subsubsection{Partition cost}

In order to evaluate a given partition $P$ at time $t$, a cost $C(P, t)$ needs
to be defined. In this paper, this cost depends on the workload in each
sector. The definitions given in~\cite{ferrari2017} are used to represent a high
(respectively normal and low) cost for partition \(P\):
\begin{equation}
  \begin{aligned}
    c_+(P, t) &= \sum_{S \in P_t} \delta_{h}(S, t) \cdot p_\text{high}^{S, t} \cdot |S|^2\\
    c_=(P, t) &= \left(
    \sum_{S \in P_t} \delta_{n}(S, t) \cdot p_{norm}^{S} \cdot |S|^{-2}
    \right)^{-1}\\
    c_-(P, t) &= \sum_{S \in P_t} \delta_{l}(S, t) \cdot p_\text{low}^{S, t} \cdot |S|^{-2}
  \end{aligned}
\end{equation}
with $\delta_{h}(P, t)$ (resp. $\delta_{n}(P_t)$ and $\delta_{l}(P_t)$) equals 1
if the probability $p_\text{high}$ (resp. $p_\text{normal}$ and $p_\text{low}$) is superior to
the two others, and 0 otherwise.

It is now possible to assign a cost to each partition. This cost is linear
regarding $c_+$, $c_=$, $c_-$ and $n$ (cardinal of the partition $P$). The
partition cost is defined as follows:
\begin{equation}
  C(P, t) = \alpha c_+ + \beta c_= + \gamma c_- +\lambda n
\end{equation}

The parameters $\alpha$, $\beta$, $\gamma$ and $\lambda$ (all positive)
determine a priority on which parameter to optimize. For instance, a high
value $\alpha$ help to
minimize $c_+$, hence the overall number of sectors with too much traffic.
In a real application, it maybe interesting to order those parameters as
follow: $\alpha > \gamma > \beta > \lambda$.

\subsubsection{Transition cost}

In an operational context, each reconfiguration increases the workload for
controllers. This needs to be considered via the definition of a transition
cost.
A transition is the difference of two partitions separated by only on time step.
The transition cost is then
\begin{equation}
  C_{tr}(P_1, P_2) =
  \begin{cases}
    0 & \text{if} \quad P_1 = P_2\\
    1 & \text{otherwise}
  \end{cases}
\end{equation}

\subsubsection{Objective function}

Having defined a cost for partitions and transitions, it is now possible to
aggregate everything in order to build a cost function over an entire
path. For a path $\pi = [P_0, \dots, P_n]$ with a time from $t_0$ to $t_n$,
the cost function is given by:
\begin{equation}
  \begin{split}
    f(\pi) = C(P_0, t_0) + \sum_{i = 1}^{n} [C(P_i, t_i) +\\
    \theta \cdot C_{tr}(P_{i-1}, P_i)]
  \end{split}
\end{equation}

with $\theta > 0$ a parameter to determine.
This is the objective function to minimize in the A$^*$ algorithm.

The Monte Carlo Tree search algorithm maximizes an objective function. This function
can be interpreted as the reward of a path.
Given the loss function defined previously, the target function can be
constructed as:
\begin{equation}
  Q(\pi) = \frac{1}{f(\pi)}
\end{equation}


\subsection{Heuristic}
To use effectively the A\(^*\) algorithm, a heuristic is needed. Using the null
heuristic (\(\forall u \in \mathcal{N}, h(u) = 0\)) -- and thus using Dijkstra
algorithm -- revealed to be inefficient
considering the branching factor. Let \(k \in \mathbb{N}\), \(u\) a node
selected at time \(k\).
The heuristic \(h(u)\) gives the cost of the path starting from \(u\) to a
leaf which is reached at a time \(t_f\).
The heuristic is built without
considering transitions (transition cost and~\ref{sssec:transitions}).
Let \(P^*_i\) be the partition with minimal cost at time \(i\), the heuristic is
then
\begin{equation}
  h(u) = \sum_{i=k+1}^f C(P^*_i, t_i)
\end{equation}
This allows to generate
the sequence of the best partitions among all possible at each time step.

\section{Results}

\subsection{Experimental setup}
For the tests, a fictitious area is used. It contains 5 elementary modules
and 12 control sectors. The resulting model tree has a mean branching factor of
6.
Regarding the branching, the smallest French area -- which is Paris West
-- has a branching factor of 16 for 20 control sectors and 12 elementary
modules. Considering the already important
branching factor, a stochastic tree search method seems appropriate.

The traffic is simulated the following way, each elementary module has an
associted list which, at index \(i\) has the number of aircraft in it at time
step \(i\). Those lists have been written by hand, the activity shows a traffic
peak at the beginning of the scenario and much less activity after. The expected
outcome of the algorithms is a massive degrouping reflecting the heavy workload
followed by merges.

\subsection{Accuracy}
Accuracy is assessed by comparing the outcome of the MCTS algorithm with the
A\(^*\) cost and a greedy algorithm cost.
The time allowed to the MCTS to run is considered long enough to allow the MCTS
to converge to its best solution. The results are summarised in
table~\ref{tab:methods_compare}.

The graph~\ref{fig:grouping} asserts the correct behaviour of both algorithms
A\(^*\) and MCTS regarding grouping and degrouping. On the \(y\) axis is
indicated the number of sectors. The two algorithms show, as expected, splits
leading from 3 sectors to 5 for the MCTS to cope with the intense trafic at
the beginning of the scenario. Both algorithm choose to merge as much as
possible to go to 1 sector.

Considering paragraph~\ref{ssec:theoretical_performances}, the MCTS should
eventually converge to the optimal value. This result reveals a flaw in the
implementation.

\begin{table}
  \centering
  \begin{tabulary}
    {\textwidth}{LRR}
    Alg. & Cost & Err.\\\toprule
    A\(^*\) & 77.31 & 0\%    \\
    MCTS    & 82.48 & 6.7\%  \\
    Greedy  & 90.50 & 17.1\% \\
  \end{tabulary}
  \caption{Comparison of several methods on the generated
  scenario.}\label{tab:methods_compare}
\end{table}

\begin{figure}
  \begin{tikzpicture}
    \begin{axis}
      [line width=0.05, mark size=0.1, xlabel=timestep, ylabel=num of sectors,
      legend entries={A\(^*\), MCTS}]
      \foreach \i in {0,1}{%
        \addplot+ table [
          x expr={\lineno}, y index=\i
          ]
          {./data/grouping.data};
      }
    \end{axis}
  \end{tikzpicture}
  \caption{Grouping profile}\label{fig:grouping}
\end{figure}
\begin{figure}
  \begin{tikzpicture}
    \begin{axis}
      [line width=0.05, mark size=0.1, xlabel=time(s), ylabel=cost]
      \addplot+ table {data/longterm.data};
      \addplot+[dashed, domain=0:10] {1268};
    \end{axis}
  \end{tikzpicture}
  \caption{The continuous line shows the total cost of a path computed by the
    MCTS algorithm. The x-axis shows the time allowed to the algorithm. The
    dashed curve is 15\% of the optimal cost found with the \(A^*\)
  algorithm.}\label{fig:longterm}
\end{figure}
\begin{figure}
  \begin{tikzpicture}
    \begin{axis}
      [line width=0.05, mark size=0.1, xlabel=time(s), ylabel=cost]
      \addplot+ table {data/shortterm.data};
    \end{axis}
  \end{tikzpicture}
  \caption{Monte Carlo tree search called with varying time allowed to compute
  each step, with a depth of 40 and \(\theta = 11\). The cost seems to be
  approximately stable from \(t=0.5\)s.}\label{fig:shortterm}
\end{figure}


\subsection{Converging speed}
Since the MCTS converges to a solution, one expects to know the time required to
be close enough to the optimal solution. To have an idea of this lapse, several
MCTS are run with different computing time. This results in a graph mapping the
time allowed to compute each step of the MCTS to the cost of the final path. To
get rid of the undesired varations due to the stochastic nature of the
algorithm, the latter process is run several times; which allows one to compute
the mean over all computed costs.

The resulting graphs are shown in figure~\ref{fig:longterm} in which it can be
seen that the algorithm reaches its best cost when it runs for 2 seconds per
step.

\begin{figure}
  \begin{tikzpicture}
    \begin{axis}
      [line width=0.05, mark size=0.1, xlabel=depth, ylabel=cost]
      \addplot+[dashed, domain=100:800] {18};
    \end{axis}
  \end{tikzpicture}
  \caption{The nice graph}\label{fig:timedepth}
\end{figure}

The converging speed may also depend on the depth of the tree searched through.
The figure~\ref{fig:timedepth} shows


\subsection{Further work}
Since all the tests has been run using Paris West area, the influence of the
complexity of the airspace has not been assessed. It would be thus relevant to
carry further tests on bigger areas. In~\cite{ferrari2017}, the time needed to
compute the cost with A\(^*\) depends heavily on the traffic itself. Therefore
the use, in this paper, of randomly generated scenarii of traffic may not be
suitable in the context of ATM\@. One can even use a more realistic workload
model such as a neural network as mentioned in~\cite{gianazza2010forecasting}.

\bibliography{article}
\bibliographystyle{plain}
\end{document}
